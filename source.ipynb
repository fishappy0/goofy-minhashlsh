{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MinHashLSH**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In local system memory implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryMinHashLSH:\n",
    "    def __init__(self, documents, k=5):\n",
    "        self.documents = documents\n",
    "        self.shingles = None\n",
    "        self.signatures = None\n",
    "        self.buckets = None\n",
    "    \n",
    "    def shingling(self, documents=pd.DataFrame([\"\"]), k=5):\n",
    "        if documents.any().any() == \"\":\n",
    "            self.documents = documents\n",
    "\n",
    "        shingles = set()\n",
    "        doc_shingles = set()\n",
    "        for doc in self.documents[\"text\"]:\n",
    "            for i in range(len(doc) - k + 1):\n",
    "                shingle = doc[i:i+k]\n",
    "                shingles.add(shingle)\n",
    "                doc_shingles.add(shingle)\n",
    "        shingles = list(shingles)\n",
    "        \n",
    "        boolean_vectors = np.full((len(self.documents), len(shingles)), False, dtype=bool)\n",
    "        for i, doc in enumerate(self.documents[\"text\"]):\n",
    "            for j, shingle in enumerate(shingles):\n",
    "                if shingle in doc:\n",
    "                    boolean_vectors[i, j] = True\n",
    "        return pd.DataFrame(boolean_vectors, columns=shingles).transpose()\n",
    "        \n",
    "    def minhashing(self, shingles_bvs, num_perm=128):\n",
    "        signatures = []\n",
    "        for _ in range(0, num_perm):\n",
    "            hash_funcs = np.random.permutation(shingles_bvs.shape[0])\n",
    "            signature = []\n",
    "            for j in range(0, shingles_bvs.shape[1]):\n",
    "                for hash in hash_funcs:\n",
    "                    if shingles_bvs.iloc[hash, j]:\n",
    "                        signature.append(hash)\n",
    "                        break\n",
    "            signatures.append(signature)\n",
    "        return pd.DataFrame(signatures)\n",
    "    \n",
    "    def locality_sensitive_hashing(self, signature, num_bands=8, num_rows=16):\n",
    "        buckets = {}\n",
    "        for i in range(0, num_bands):\n",
    "            band = signature.iloc[i*num_rows:(i+1)*num_rows]\n",
    "            for j in range(0, band.shape[1]):\n",
    "                hashed_band = hash(tuple(band.iloc[:, j]))\n",
    "                if hashed_band in buckets:\n",
    "                    buckets[hashed_band].append(j)\n",
    "                else:\n",
    "                    buckets[hashed_band] = [j]\n",
    "        return buckets\n",
    "\n",
    "    def run(self, documents=\"\"):\n",
    "        if documents != \"\":\n",
    "            self.documents = documents\n",
    "        self.shingles = self.shingling(self.documents)\n",
    "        self.signatures = self.minhashing(self.shingles)\n",
    "        self.buckets = self.locality_sensitive_hashing(self.signatures)\n",
    "        return self.buckets\n",
    "    \n",
    "    def __jaccard_similarity(self, a, b):\n",
    "        return len(a & b) / len(a | b)\n",
    "    \n",
    "    def approximateNearestNeighbors(self, key, n):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1379140599642863165: [0, 2], 9040997445242030420: [1], -2011539986988155481: [3], 5927102016616960046: [0, 2], -7896971630727833918: [1], 4934936327892699789: [3], 244299711004002593: [0, 2], 7666908281629136108: [1], -9161432108047039538: [3], 8331251141106009057: [0, 2], 7309846408532718783: [1], -4169070300030851549: [3], 538062161962066744: [0, 2], -8568018872202180160: [1], -6376555837399552003: [3], 5925910462200784584: [0, 2], -4604407864863100061: [1], 6162459667513325389: [3], -2954536926530557813: [0, 2], 6257829669100608064: [1], 7776162716060853749: [3], 6853229475000010218: [0, 2], 6361141334233927601: [1], -8053711553699312521: [3]}\n"
     ]
    }
   ],
   "source": [
    "test_docs = [\"This is a test document\", \"This document is another test document\", \"This is a test document\", \"Hello word\"]\n",
    "docs_df = pd.DataFrame(test_docs, columns=[\"text\"])\n",
    "in_memory_lsh = InMemoryMinHashLSH(docs_df)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# bool_vecs = in_memory_lsh.shingling()\n",
    "# sigs = in_memory_lsh.minhashing(bool_vecs, 128)\n",
    "# buckets = in_memory_lsh.locality_sensitive_hashing(sigs)\n",
    "buckets = in_memory_lsh.run()\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F \n",
    "class SparkMinHashLSH:\n",
    "    def __init__(self, documents, k=5):\n",
    "        self.documents = documents\n",
    "    \n",
    "    def shingling(self,documents=\"\", k=5):\n",
    "        if documents != \"\":\n",
    "            self.documents = documents\n",
    "\n",
    "        # documents_rdd = self.documents.rdd.map(lambda x: x[0])\n",
    "        # shingles = documents_rdd.flatMap(lambda x: list(set([x[i:i+k] for i in range(len(x) - k + 1)])))\n",
    "        # doc_shingles = documents_rdd.map(lambda x: list(set([x[i:i+k] for i in range(len(x) - k + 1)])))\n",
    "        # bool_vecs = doc_shingles.leftOuterJoin(shingles)\n",
    "        # bool_vecs = shingles.join(doc_shingles, on=\"shingles\", how=\"left\").fillna(0)\n",
    "        # return shingles\n",
    "        # ohe = OneHotEncoder(inputCol=\"shingles\", outputCol=\"shingles_ohe\")\n",
    "        # return bool_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"minHashLSH\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"This is a test document\",), (\"This document is another test document\",), (\"This is a test document\",), (\"Hello wordello \",)]\n",
    "df = spark.createDataFrame(data, [\"text\"])\n",
    "# spark_lsh = SparkMinHashLSH(df)\n",
    "# spark_lsh.shingling().take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, hashlib, math, time\n",
    "from random import randint, seed\n",
    "seed(16)\n",
    "\n",
    "\n",
    "class hashFamily:\n",
    "    def __init__(self, i):\n",
    "        self.resultSize = 8 # how many bytes we want back\n",
    "        self.maxLen = 20 # how long can our i be (in decimal)\n",
    "        self.salt = str(i).zfill(self.maxLen)[-self.maxLen:]\n",
    "        self.id = i\n",
    "        \n",
    "    def get_hash_value(self, el_to_hash):\n",
    "        return int(hashlib.sha1(str(el_to_hash).encode('utf-8') + self.salt.encode('utf-8')).hexdigest()[-self.resultSize:], 16)\n",
    "    \n",
    "\n",
    "hash_family = hashFamily(0)\n",
    "assert hash_family.get_hash_value(\"test\") == hash_family.get_hash_value(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
